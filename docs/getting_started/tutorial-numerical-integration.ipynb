{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Numerical Integration Methods\n",
    "\n",
    "The estimation of Dynamic Discrete Choice Models (DDCM) is often constrained by computational constraints. For example, Keane and Wolpin (1997) and subsequent work that estimates DDCM's of post-graduation career dynamics abstract from many important determinants of earnings and mobility dynamics. Examples include the abstraction from match heterogeneity, permanent skill shocks, and failure to account appropriately for multidimensional skill structures.\n",
    "\n",
    "Keane and Wolpin (1994, 1997) split their occupational classes into white- and blue-collar occupations. Nevertheless, empirical evidence suggests that skill requirements vary substantially within blue- and white-collar occupations. Arguably any aggregation of occupational classes should be able to account for meaningful skill differences. Acemoglu and Autor (2011) suggest four aggregate groups that are explicitly derived from the task content of classified three digit occupations in US data.[<sup>1</sup>](#fn1)\n",
    "\n",
    "Adding elements alike enlarges the computational burden of solving a model alike enormously, and as already Keane and Wolpin (1994) noted, \"[...] for problems of the size we would like to consider a [...] simulation strategy is not computationally practicable.\" A primary bottleneck in solving and estimating DDCM's is the solution of the expected value function, the so-called $EMax(\\cdot)$, which was usually undertaken by means of a Monte-Carlo simulation. Adding new features to the model increases the required number of function evaluations, which are the costly operation in numerical integration. Results from applied mathematics suggest methods that are more efficient and thus enable a performance increase. For the same number of function evaluations, quasi-Monte Carlo methods achieve a significantly higher accuracy.\n",
    "\n",
    "With ``respy`` you are able to employ Quasi-Monte Carlo methods to solve and estimate DDCM's. This notebook contains a tutorial on how to specify the numerical integration option in ``respy``. For expositional purposes we will rely on the KW 1994 model. The following sections:\n",
    "\n",
    "- Will explain how to choose the Monte Carlo Method in respy.\n",
    "- Provide a Simulation study: How does the integration method affects the solution of the model?\n",
    "- Will describe how to choose the number of iterations.\n",
    "\n",
    "The following [slides](https://github.com/HumanCapitalAnalysis/student-project-rafael_suchy/blob/master/slides/numerical_integration_ddcm.pdf) give a gentle introduction into the KW (1994) model and highlight its main components. Additionally the reason and basic intuition for the usage of Monte Carlo and Quasi-Monte Carlo methods are outlined. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'auxiliary_figures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-729818e5b6a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mauxiliary_figures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mauxiliary_integration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'auxiliary_figures'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import respy as rp\n",
    "import numpy as np\n",
    "\n",
    "from auxiliary_figures import *\n",
    "from auxiliary_integration import *\n",
    "from time import time\n",
    "#plt.style.use(\"../_static/respy.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Integration in respy\n",
    "\n",
    "The current functionality of ``respy`` entails two main methods for the numerical approximation of the $EMax(\\cdot)$:\n",
    "-\tMonte Carlo Simulation: Chooses points randomly in the domain \n",
    "-\tQuasi Monte Carlo Simulation: Chooses points from one of the two low-discrepancy sequences\n",
    "        - Sobol\n",
    "        - Halton\n",
    "        \n",
    "A very short introduction about the nature of low-discrepancy sequences is provided in the following [notebook](https://github.com/HumanCapitalAnalysis/student-project-rafael_suchy/blob/master/notebooks/98_low_discrepancy_sequences_application_integration.ipynb).\n",
    "\n",
    "Now it is finally time to get our hands on the implementation in ``respy``. The main method affected is ``create_base_draws`` within ``shared.py``, which as the name suggests creates a set of draws from the standard normal distribution. The draws are either drawn randomly (Monte Carlo Simulation) or from low-discrepancy sequences (Quasi-Monte Carlo Simulation). Either of the methods is used to calculate the $EMax(\\cdot)$ in the solution *and* the choice probabilities in the maximum likelihood estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose the Monte Carlo Method in respy.\n",
    "\n",
    "As mentioned, we will use the KW (1994) model within this tutorial. First, we get the parametrization of the KW(1994) model. For details, you are welcomed to consult the previous tutorials of this readme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, options = rp.get_example_model(\"kw_94_one\", with_data = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of *options* helps to define the underlying model and characterizes the solution methods as well as some functional forms. Inspecting the content we recognize the relevant options `solution_draws` and `monte_carlo_sequence`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimation_draws': 200,\n",
       " 'estimation_seed': 500,\n",
       " 'estimation_tau': 500,\n",
       " 'interpolation_points': -1,\n",
       " 'n_periods': 40,\n",
       " 'simulation_agents': 1000,\n",
       " 'simulation_seed': 132,\n",
       " 'solution_draws': 500,\n",
       " 'solution_seed': 1,\n",
       " 'monte_carlo_sequence': 'random',\n",
       " 'core_state_space_filters': [\"period > 0 and exp_{i} == period and lagged_choice_1 != '{i}'\",\n",
       "  \"period > 0 and exp_a + exp_b + exp_edu == period and lagged_choice_1 == '{j}'\",\n",
       "  \"period > 0 and lagged_choice_1 == 'edu' and exp_edu == 0\",\n",
       "  \"lagged_choice_1 == '{k}' and exp_{k} == 0\",\n",
       "  \"period == 0 and lagged_choice_1 == '{k}'\"],\n",
       " 'covariates': {'constant': '1',\n",
       "  'exp_a_square': 'exp_a ** 2',\n",
       "  'exp_b_square': 'exp_b ** 2',\n",
       "  'at_least_twelve_exp_edu': 'exp_edu >= 12',\n",
       "  'not_edu_last_period': \"lagged_choice_1 != 'edu'\",\n",
       "  'edu_ten': 'exp_edu == 10'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The option `solution_draws` specifies how many points are simulated in order to solve the model. Ceteris paribus, choosing more points leads to a higher accuracy but also to higher computational costs. The option `monte_carlo_sequence` determines the method.[<sup>2</sup>](#fn2) As we will see, the implementation of Quasi-Monte Carlo methods enables to break the trade-off: It is possible to increase the accuracy for a given set of points, switching from Monte Carlo methods to Quasi-Monte Carlo methods.\n",
    "\n",
    "Currently is is possible to choose `monte_carlo_sequence` from the set of $\\{$\"random\", \"halton\", \"sobol\" $\\}$. In the following we will use the Sobol sequence with 200 draws to solve the model (`rp.solve`), by changing the option parameters as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "options[\"monte_carlo_sequence\"], options[\"solution_draws\"]  = [\"sobol\", 200]\n",
    "state_space = rp.solve(params, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify, we can shortly check whether the options were changed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sobol', 200)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options[\"monte_carlo_sequence\"], options[\"solution_draws\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, the relevant methods for changing the methods are mentioned. Hence, the eager reader can start to experiment with its own model (or a different Keane and Wolping specification). In the next section we will provide an example and simulate the KW(1994) with different options. We will elaborate on how the employed Monte Carlo Methods affects the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation study: How does the integration method affects the solution of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simulate the model with either of the methods: \"random\", \"halton\", \"sobol\" and vary the amount of points from `POINTS_MIN` to `POINTS_MAX` by increments of (`POINTS_MAX` -  `POINTS_MIN`)/`NUM_EVALS` that are used in the solution of the model. A reference value is calculated by using a very large amount of points ``POINTS_TRUTH``. Note, solving the whole model with ``POINTS_TRUTH`` repeatedly would not be possible at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS_TRUTH = 10_000_000   \n",
    "\n",
    "POINTS_MIN = 100        # minimum number of points\n",
    "POINTS_MAX = 10_000     # maximum number of points\n",
    "NUM_EVALS = 100         # number of evaluations\n",
    "POINTS_GRID = np.linspace(POINTS_MIN, POINTS_MAX, NUM_EVALS, dtype = int)\n",
    "\n",
    "METHODS = [\"random\", \"halton\", \"sobol\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will compute a reference value for the $EMax(\\cdot)$ values by using a large amount of points with the \"sobol\"-sequence. We extract the \"true\" $EMax(\\cdot)$ values into the object `emax_true`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <b>Caution:</b> Execution may take some time.\n",
    "</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options[\"monte_carlo_sequence\"], options[\"solution_draws\"]  = [\"sobol\", POINTS_TRUTH] \n",
    "\n",
    "state_space = rp.solve(params, options)\n",
    "emax_true = state_space.emax_value_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we will loop over the methods and the number of points to calculate the $EMax(\\cdot)$ for each specification of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <b>Caution:</b> Execution may take even some more time. <br>\n",
    "    Alternatively, you can load the results from the pre-simulated pickle-files.\n",
    "</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-446e5f5db2dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_emax_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOINTS_GRID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_exec_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOINTS_GRID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"monte_carlo_sequence\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_emax_values = pd.DataFrame(index = POINTS_GRID, columns = METHODS)\n",
    "df_exec_time = pd.DataFrame(index = POINTS_GRID, columns = METHODS)\n",
    "\n",
    "for method in METHODS:\n",
    "    options[\"monte_carlo_sequence\"] = method\n",
    "    print(\"Current Iteration:\", method.capitalize(), \".\")\n",
    "    for points in POINTS_GRID:\n",
    "        options[\"solution_draws\"] = points\n",
    "        state_space = rp.solve(params, options)\n",
    "        df_emax_values.loc[points][method] = state_space.emax_value_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to choose the number of iterations?\n",
    "\n",
    "Already in 1975 Hoaglin and Andrews set up recommendations how to report results and procedures when performing simulation studies. Hauck and Anderson (1984) surveyed 1,198 papers in five major statistical journals where 216 provided results that were based on simulation. But only 9% of papers that used a simulation study justified the choice of the number of iterations, finding little support for the recommendations by Hoaglin and Andrews.[<sup>3</sup>](#fn3) \n",
    "\n",
    "Harwell (2018) provide an update of the survey. The authors survey studies in six statistics journals between 1985 and 2012 and confirm that the use of simulation studies had doubled since 1984. An improvement of reporting standards is not the case: Less than 18 of 371 simulation studies used an experimental design that could be identified. Additionally, 99.9% of the studies relied on a visual analysis, aka. eyeballing, of the results. In this section we will provide some first ideas how to substantiate the number of iterations within (quasi-)Monte Carlo simulations.\n",
    "\n",
    "### Iterations for Monte Carlo Analysis \n",
    "\n",
    "The variance expression of MC methods can guide our calculation of the number of iterations. Suppose we simulate $N$ samples (iterations) then the variance obtained by the MC procedure is approximately given by\n",
    "\n",
    "$$\n",
    "    \\dfrac{\\sigma^2(f)}{N}.\n",
    "$$\n",
    "\n",
    "A-priori, the value of $\\sigma^2(f)$ is unknown but can be estimated via MC. As in our example with `POINTS_TRUTH` the first step includes a MC analysis with a very large amount of iterations. Having a desired precision $\\rho$ in mind, it would be necessary to perform \n",
    "\n",
    "$$\n",
    "    \\sqrt{M} \\approx \\dfrac{\\sigma}{\\rho}\n",
    "$$\n",
    "\n",
    "number of iterations.[<sup>4</sup>](#fn4) \n",
    "\n",
    "Another less scientific approach acknowledges the diversity of problems than can be tackled with Monte Carlo simulation. A fixed number of iterations may serve as a guideline and substantiated reasoning for a first implementation. Nevertheless, quantifying extremely small probabilities needs a different amount of iterations than quantifying a mean. Hence, one may wish to manually adjust. Bukaçi et al. (2016) propose a method that is based on convergence plots. As in our example, it is necessary to calculate the value of interest (for example the value of the $EMax(\\cdot)$) using different number of iterations. Following Bukaçi et al. (2016) the number of iterations at which the MC method becomes stable can be used in the simulation study.\n",
    "\n",
    "### Iterations for quasi-Monte Carlo Analysis \n",
    "\n",
    "Due to the completely deterministic nature of quasi-Monte Carlo methods (integration) we eventually obtain deterministic, and hence guaranteed error bounds. Theoretically, it is always possible to determine an integration rule that yields a prescribed level of accuracy. To reiterate, with the same computational effort (same number of function evaluations) the quasi-Monte Carlo methods achieve a higher accuracy than the MC method. Hence, having a number of iterations for the Monte Carlo method, we certainly know that employing a quasi-Monte Carlo procedure will perform better. \n",
    "\n",
    "Formally we can use the Koksma-Hlawka inequality to determina an error bound of Quasi-Monte Carlo methods.[<sup>5</sup>](#fn5) If the random variable (integrand) $f$ has bounded variance $\\mathbb{V}(f)$ on $\\bar{I}^d$, then for any $x_1, \\dots, x_N \\in \\bar{I}^d$ we have \n",
    "\n",
    "$$\n",
    "    \\left| \\dfrac{1}{N} \\sum_{i=1}^N f(x_i) - \\int_{\\bar{I}^d} f(u) \\mathrm{d}u ~\\right| \\leq \\mathbb{V}(f) D_N^*(x_1, \\dots, x_N),\n",
    "$$\n",
    "\n",
    "where $D_N^*$ denotes the star discrepancy[<sup>6</sup>](#fn6) of the nodes.\n",
    "\n",
    "If all expressions in Koksma-Hlawka inequality can be calculated then specifying a desired precision and solving for the number of iterations $N$ yields the desired result. The world could be so easy if the derivation of the Koksma-Hlawka inequality would not point towards a drawback: it does not apply to functions with simple discontinuities. To circumvent, Brandolini et al. (2013) derive a Koksma-Hlawka-type inequality which applies to piecewise smooth functions. Nevertheless, oftentimes it is not feasible to calculate the expressions directly - in our case it is at least difficult. \n",
    "\n",
    "However, the Koksma-Hlawka inequality offers an additional insight: point sets with a small discrepancy guarantee small errors when using quasi-Monte Carlo methods for numerial integration. Number generators based on integer arithmetic module two, as the Sobol-sequence, provide additional equidistribution properties *whenever* the number of iterations $N$ is a power of two, $N = 2^n- 1$. Specifically, our [notebook](https://github.com/HumanCapitalAnalysis/student-project-rafael_suchy/blob/master/notebooks/98_low_discrepancy_sequences_application_integration.ipynb) demonstrates that those sequences are only equidistant, and hence have the minimal star discrepancy, if we have $N = 2^n – 1$ iterations.[<sup>7</sup>](#fn7)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST OF ROBINSON FOR REFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import respy as rp\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "plt.style.use(\"../_static/respy.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df.groupby(\"Period\").Choice.value_counts(normalize=True).unstack().plot.bar(\n",
    "    stacked=True, ax=ax, color=[\"C0\", \"C2\", \"C1\"],\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=\"horizontal\")\n",
    "\n",
    "plt.legend(loc=\"lower center\", bbox_to_anchor=(0.5,-0.275), ncol=3)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "\n",
    "<span id=\"fn1\"><sup>1</sup>\n",
    "    Over the last few decades the empirical literature established a relatively weak economic performance of occupations that require workers to solve routine cognitive or routine manual tasks. Dimensions of occupational skill requirements, skill prices, and employment shares evolved substantially in the last years. As the authors suggest, distinction between   \n",
    "    $~~~~~$ a) abstract, non-routine tasks (e.g. managerial)   \n",
    "    $~~~~~$ b) routine cognitive tasks (e.g. adminstrative and sales),   \n",
    "    $~~~~~$ c) routine manual tasks (e.g. production),    \n",
    "    $~~~~~$ d) non-routine manual tasks (e.g. service occupations).   \n",
    "may be more appropriate \n",
    "</span>\n",
    "\n",
    "<span id=\"fn2\"><sup>2</sup>\n",
    "    Please do not get confused. Although the option name is called `monte_carlo_sequence` it does indeed inlcude the Quasi-Monte Carlo methods. The naming convenation was chosen this way, because in ``respy`` we regard Monte Carlo methods as the aggregate group. \n",
    "</span>\n",
    "\n",
    "<span id=\"fn3\"><sup>3</sup>\n",
    "    A review of papers within Economics would probably indicate a similar state.   \n",
    "</span>\n",
    "\n",
    "\n",
    "<span id=\"fn4\"><sup>4</sup>\n",
    "    See [Niederreiter (1992)](https://epubs.siam.org/doi/book/10.1137/1.9781611970081) for a thorough treatment including methods for variance reduction.\n",
    "</span>\n",
    "\n",
    "<span id=\"fn5\"><sup>5</sup>\n",
    "    A derivation can be found at pp.19f in [Niederreiter (1992)](https://epubs.siam.org/doi/book/10.1137/1.9781611970081).\n",
    "</span>\n",
    "\n",
    "\n",
    "<span id=\"fn6\"><sup>6</sup>\n",
    "    See[Niederreiter (1992)](https://epubs.siam.org/doi/book/10.1137/1.9781611970081) p.14 for the definition.\n",
    "</span>\n",
    "\n",
    "<span id=\"fn7\"><sup>7</sup>\n",
    "    If 0 is explicitly included in the construction of the sequence then the term “$-1$” can be dropped.\n",
    "</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Appendix: Notation on (quasi-)Monte Carlo approximation\n",
    "\n",
    "This section will serve as a short introduction into the notation, especially why $f$ can be treated as function (integrand) and as random variable.\n",
    "\n",
    "For discussion of an approximate calculation of the integral $\\int_{\\mathbb{D}} f(u) \\mathrm{d}u$ we will assume that the integration domain $\\mathbb{D} \\subseteq \\mathbb{R}^d$ satisfies $0 < \\lambda_d(\\mathbb{D}) < \\infty$. We denote the d-dimensional Lebesgue measure with $\\lambda_d$. \n",
    "\n",
    "By defining the probability meaure $\\mathrm{d}\\mu = \\dfrac{\\mathrm{du}}{\\lambda_d(\\mathbb{D})}$ we turn the domain $\\mathbb{D}$ into a probability space. In this notation we can rewrite the integral as \n",
    "\n",
    "$$ \n",
    "    \\int_{\\mathbb{D}} f(u) \\mathrm{d}u = \\lambda_d(\\mathbb{D}) f \\mathrm{d}\\mu = \\lambda_d(\\mathbb{D}) \\mathbb{E}[f], \n",
    "$$\n",
    "\n",
    "where $\\mathbb{E}[f]$ denotes the expected value of the random variable $f$.  The Monte Carlo estimate for the expected value $\\mathbb{E}[f]$ is obtained by taking $N$ independent $\\lambda$-distributed random samples $s_1, \\dots, s_N$ from the domain $A$ of the random variable $f$ and let \n",
    "\n",
    "$$ \n",
    "    \\mathbb{E}[f] \\approx \\dfrac{1}{N} \\sum_{i=1}^N f(s_i).\n",
    "$$\n",
    "\n",
    "Although this discussion should only introduce some notation we use in the analysis of variance, a derivation (as provided in Niederreiter) shows that we can formalize the Monte Carlo estimate as follows\n",
    "\n",
    "$$ \n",
    "\\int_{\\mathbb{D}} f(u) \\mathrm{d}u \\approx \\dfrac{1}{N} \\sum_{i=1}^N f(y_i),\n",
    "$$\n",
    "\n",
    "The nodes $y_i, \\dots, y_N$ are $N$ independent random samples from a uniform distribution on $\\bar{I}^d$, where $\\bar{I}^d$ denotes the closed d-dimensional unit cube. We have a probabilistic error bound of $O(N^{-1/2})$.\n",
    "\n",
    "The quasi-Monte Carlo approximation looks formally like the MC estimate but is used with deterministic nodes $x_1, \\dots, x_N  \\in \\bar{I}^d$. We take $\\mathbb{D}$ as a subset of $\\bar{I}^d$ and choose deterministic points $x_1, \\dots, x_N \\in \\mathbb{D}$.  The QMC approximation is given by\n",
    "\n",
    "$$\n",
    "\\int_\\mathbb{D} f(u) \\mathrm{d}u \\approx \\dfrac{1}{N} \\sum_{i=1}^N f(x_i).\n",
    "$$\n",
    "\n",
    "We get a deterministic error bound of $O(N^{-1}(log(N))^{d-1})$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "> Acemoglu, D. and D. Autor (2011). [Skills, Tasks and Technologies: Implications for Employment and Earnings](https://economics.mit.edu/files/7006). *Handbook of Labor Economics*, Chapter 12, Vol. 4b.\n",
    "\n",
    "> Bukaçi, E. et al. (2016). [Number of iterations needed in Monte Carlo Simulation using reliability analysis for tunnel supports](https://www.ijera.com/papers/Vol6_issue6/Part%20-%203/J0606036064.pdf). *International Journal of Engineering Research and Applications*, 6(6): pp.60-64.\n",
    "\n",
    "> Brandolini, L., Colzani, L., Gigante, G. and Travaglini, G. (2013). [On the Koksma–Hlawka inequality](https://www.sciencedirect.com/science/article/pii/S0885064X12000854#b000005). *Journal of Complexity*, 29(2): 158-172.\n",
    "\n",
    "> Hauck, W.H., and Anderson, S. (1984). [A Survey Regarding the Reporting of Simulation Studies](https://amstat.tandfonline.com/doi/abs/10.1080/00031305.1984.10483206#.XjP298hKiUk). *The American Statistician*, 38(3): 214–216.\n",
    "\n",
    "> Hoaglin, D.C., and Andrews, D.F. (1975). [The Reporting of Computation-Based Results in Statistics](https://www.tandfonline.com/doi/citedby/10.1080/00031305.1975.10477393?scroll=top&needAccess=true). *The American Statistician*, 29(3): 122–126.  \n",
    "\n",
    "> Harwell, M., Nidhi, K. and Peralta-Torres, Y. (2018). [A Survey of Reporting Practices of Computer Simulation Studies in Statistical Research](https://www.tandfonline.com/doi/full/10.1080/00031305.2017.1342692?scroll=top&needAccess=true). *The American Statistician*, 72(4), pp.321-327.\n",
    "\n",
    "> Keane, M.P. and Wolpin, K.I. (1997). [The Career Decisions of Young Men](https://doi.org/10.1086/262080). *Journal of Political Economy*, 105(3): 473-522.\n",
    "\n",
    "> Niederreiter, H. (1992). [Random Number Generation and Quasi-Monte Carlo Methods](https://epubs.siam.org/doi/book/10.1137/1.9781611970081). *CBMS-NSF Regional Conference Series in Applied Mathematics*.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
